@book{zabczyk2020mathematical,
  title={Mathematical control theory},
  author={Zabczyk, Jerzy},
  year={2020},
  publisher={Springer}
}

@article{HU2022111554,
title = {Optimal temperature ranges considering gender differences in thermal comfort, work performance, and sick building syndrome: A winter field study in university classrooms},
journal = {Energy and Buildings},
volume = {254},
pages = {111554},
year = {2022},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2021.111554},
url = {https://www.sciencedirect.com/science/article/pii/S0378778821008380},
author = {Jinhua Hu and Yingdong He and Xiaoli Hao and Nianping Li and Yuan Su and Huaidi Qu},
keywords = {Gender differences, Comfort temperature, Work performance, Sick building syndrome, Indoor environmental quality}
}

@article{tonmoy2024comprehensive,
  title={A comprehensive survey of hallucination mitigation techniques in large language models},
  author={Tonmoy, SM and Zaman, SM and Jain, Vinija and Rani, Anku and Rawte, Vipula and Chadha, Aman and Das, Amitava},
  journal={arXiv preprint arXiv:2401.01313},
  year={2024}
}

@article{zhang2023retrieve,
  title={Retrieve anything to augment large language models},
  author={Zhang, Peitian and Xiao, Shitao and Liu, Zheng and Dou, Zhicheng and Nie, Jian-Yun},
  journal={arXiv preprint arXiv:2310.07554},
  year={2023}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{DBLP:journals/corr/VaswaniSPUJGKP17,
  author       = {Ashish Vaswani and
                  Noam Shazeer and
                  Niki Parmar and
                  Jakob Uszkoreit and
                  Llion Jones and
                  Aidan N. Gomez and
                  Lukasz Kaiser and
                  Illia Polosukhin},
  title        = {Attention Is All You Need},
  journal      = {CoRR},
  volume       = {abs/1706.03762},
  year         = {2017},
  url          = {http://arxiv.org/abs/1706.03762},
  eprinttype    = {arXiv},
  eprint       = {1706.03762},
  timestamp    = {Sat, 23 Jan 2021 01:20:40 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{ronneberger2015unetconvolutionalnetworksbiomedical,
      title={U-Net: Convolutional Networks for Biomedical Image Segmentation}, 
      author={Olaf Ronneberger and Philipp Fischer and Thomas Brox},
      year={2015},
      eprint={1505.04597},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1505.04597}, 
}

@misc{bubeck2023sparksartificialgeneralintelligence,
      title={Sparks of Artificial General Intelligence: Early experiments with GPT-4}, 
      author={Sébastien Bubeck and Varun Chandrasekaran and Ronen Eldan and Johannes Gehrke and Eric Horvitz and Ece Kamar and Peter Lee and Yin Tat Lee and Yuanzhi Li and Scott Lundberg and Harsha Nori and Hamid Palangi and Marco Tulio Ribeiro and Yi Zhang},
      year={2023},
      eprint={2303.12712},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.12712}, 
}

@article{metalearning,
  author       = {Timothy M. Hospedales and
                  Antreas Antoniou and
                  Paul Micaelli and
                  Amos J. Storkey},
  title        = {Meta-Learning in Neural Networks: {A} Survey},
  journal      = {CoRR},
  volume       = {abs/2004.05439},
  year         = {2020},
  url          = {https://arxiv.org/abs/2004.05439},
  eprinttype    = {arXiv},
  eprint       = {2004.05439},
  timestamp    = {Tue, 14 Apr 2020 16:40:34 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2004-05439.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{wiles2021finegrainedanalysisdistributionshift,
      title={A Fine-Grained Analysis on Distribution Shift}, 
      author={Olivia Wiles and Sven Gowal and Florian Stimberg and Sylvestre Alvise-Rebuffi and Ira Ktena and Krishnamurthy Dvijotham and Taylan Cemgil},
      year={2021},
      eprint={2110.11328},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2110.11328}, 
}

@article{Yao2018TakingHO,
  title={Taking Human out of Learning Applications: A Survey on Automated Machine Learning},
  author={Quanming Yao and Mengshuo Wang and Hugo Jair Escalante and Isabelle M Guyon and Yi-Qi Hu and Yu-Feng Li and Wei-Wei Tu and Qiang Yang and Yang Yu},
  journal={ArXiv},
  year={2018},
  volume={abs/1810.13306},
  url={https://api.semanticscholar.org/CorpusID:260441722}
}

@article{foundationalmodels,
  author       = {Rishi Bommasani and
                  Drew A. Hudson and
                  Ehsan Adeli and
                  Russ B. Altman and
                  Simran Arora and
                  Sydney von Arx and
                  Michael S. Bernstein and
                  Jeannette Bohg and
                  Antoine Bosselut and
                  Emma Brunskill and
                  Erik Brynjolfsson and
                  Shyamal Buch and
                  Dallas Card and
                  Rodrigo Castellon and
                  Niladri S. Chatterji and
                  Annie S. Chen and
                  Kathleen Creel and
                  Jared Quincy Davis and
                  Dorottya Demszky and
                  Chris Donahue and
                  Moussa Doumbouya and
                  Esin Durmus and
                  Stefano Ermon and
                  John Etchemendy and
                  Kawin Ethayarajh and
                  Li Fei{-}Fei and
                  Chelsea Finn and
                  Trevor Gale and
                  Lauren Gillespie and
                  Karan Goel and
                  Noah D. Goodman and
                  Shelby Grossman and
                  Neel Guha and
                  Tatsunori Hashimoto and
                  Peter Henderson and
                  John Hewitt and
                  Daniel E. Ho and
                  Jenny Hong and
                  Kyle Hsu and
                  Jing Huang and
                  Thomas Icard and
                  Saahil Jain and
                  Dan Jurafsky and
                  Pratyusha Kalluri and
                  Siddharth Karamcheti and
                  Geoff Keeling and
                  Fereshte Khani and
                  Omar Khattab and
                  Pang Wei Koh and
                  Mark S. Krass and
                  Ranjay Krishna and
                  Rohith Kuditipudi and
                  et al.},
  title        = {On the Opportunities and Risks of Foundation Models},
  journal      = {CoRR},
  volume       = {abs/2108.07258},
  year         = {2021},
  url          = {https://arxiv.org/abs/2108.07258},
  eprinttype    = {arXiv},
  eprint       = {2108.07258},
  timestamp    = {Mon, 05 Aug 2024 15:41:34 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2108-07258.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@article{Luther2024,
  title = {Teaming Up with an AI: Exploring Human–AI Collaboration in a Writing Scenario with ChatGPT},
  volume = {5},
  ISSN = {2673-2688},
  url = {http://dx.doi.org/10.3390/ai5030065},
  DOI = {10.3390/ai5030065},
  number = {3},
  journal = {AI},
  publisher = {MDPI AG},
  author = {Luther,  Teresa and Kimmerle,  Joachim and Cress,  Ulrike},
  year = {2024},
  month = aug,
  pages = {1357–1376}
}

@article{XinXiaCao2023,
  title={A new era of intelligent interaction: Opportunities and challenges brought by ChatGPT},
  author={XinXia Cao},
  journal={Geographical Research Bulletin},
  volume={2},
  number={ },
  pages={162-165},
  year={2023},
  doi={10.50908/grb.2.0_162}
}

@article{Herbold2023,
  title = {A large-scale comparison of human-written versus ChatGPT-generated essays},
  volume = {13},
  ISSN = {2045-2322},
  url = {http://dx.doi.org/10.1038/s41598-023-45644-9},
  DOI = {10.1038/s41598-023-45644-9},
  number = {1},
  journal = {Scientific Reports},
  publisher = {Springer Science and Business Media LLC},
  author = {Herbold,  Steffen and Hautli-Janisz,  Annette and Heuer,  Ute and Kikteva,  Zlata and Trautsch,  Alexander},
  year = {2023},
  month = oct 
}

@article{Dynel2023,
  title = {Lessons in linguistics with ChatGPT: Metapragmatics,  metacommunication,  metadiscourse and metalanguage in human-AI interactions},
  volume = {93},
  ISSN = {0271-5309},
  url = {http://dx.doi.org/10.1016/j.langcom.2023.09.002},
  DOI = {10.1016/j.langcom.2023.09.002},
  journal = {Language and Communication},
  publisher = {Elsevier BV},
  author = {Dynel,  Marta},
  year = {2023},
  month = nov,
  pages = {107–124}
}

@article{Sternberg2012,
  title = {Intelligence},
  volume = {14},
  ISSN = {1958-5969},
  url = {http://dx.doi.org/10.31887/DCNS.2012.14.1/rsternberg},
  DOI = {10.31887/dcns.2012.14.1/rsternberg},
  number = {1},
  journal = {Dialogues in Clinical Neuroscience},
  publisher = {Informa UK Limited},
  author = {Sternberg,  Robert J.},
  year = {2012},
  month = mar,
  pages = {19–27}
}

@article{brown1992class,
  title={Class-based n-gram models of natural language},
  author={Brown, Peter F and Della Pietra, Vincent J and Desouza, Peter V and Lai, Jennifer C and Mercer, Robert L},
  journal={Computational linguistics},
  volume={18},
  number={4},
  pages={467--480},
  year={1992}
}

@article{Vinyals2019,
  title = {Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  volume = {575},
  ISSN = {1476-4687},
  url = {http://dx.doi.org/10.1038/s41586-019-1724-z},
  DOI = {10.1038/s41586-019-1724-z},
  number = {7782},
  journal = {Nature},
  publisher = {Springer Science and Business Media LLC},
  author = {Vinyals,  Oriol and Babuschkin,  Igor and Czarnecki,  Wojciech M. and Mathieu,  Michaël and Dudzik,  Andrew and Chung,  Junyoung and Choi,  David H. and Powell,  Richard and Ewalds,  Timo and Georgiev,  Petko and Oh,  Junhyuk and Horgan,  Dan and Kroiss,  Manuel and Danihelka,  Ivo and Huang,  Aja and Sifre,  Laurent and Cai,  Trevor and Agapiou,  John P. and Jaderberg,  Max and Vezhnevets,  Alexander S. and Leblond,  Rémi and Pohlen,  Tobias and Dalibard,  Valentin and Budden,  David and Sulsky,  Yury and Molloy,  James and Paine,  Tom L. and Gulcehre,  Caglar and Wang,  Ziyu and Pfaff,  Tobias and Wu,  Yuhuai and Ring,  Roman and Yogatama,  Dani and W\"{u}nsch,  Dario and McKinney,  Katrina and Smith,  Oliver and Schaul,  Tom and Lillicrap,  Timothy and Kavukcuoglu,  Koray and Hassabis,  Demis and Apps,  Chris and Silver,  David},
  year = {2019},
  month = oct,
  pages = {350–354}
}

@book{Anderson2013,
  title = {The Architecture of Cognition},
  ISBN = {9781317759539},
  url = {http://dx.doi.org/10.4324/9781315799438},
  DOI = {10.4324/9781315799438},
  publisher = {Psychology Press},
  author = {Anderson,  John R.},
  year = {2013},
  month = nov 
}

@misc{emotionalstimuli,
  doi = {10.48550/ARXIV.2307.11760},
  url = {https://arxiv.org/abs/2307.11760},
  author = {Li,  Cheng and Wang,  Jindong and Zhang,  Yixuan and Zhu,  Kaijie and Hou,  Wenxin and Lian,  Jianxun and Luo,  Fang and Yang,  Qiang and Xie,  Xing},
  keywords = {Computation and Language (cs.CL),  Artificial Intelligence (cs.AI),  Human-Computer Interaction (cs.HC),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Large Language Models Understand and Can be Enhanced by Emotional Stimuli},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{boundingcapacities,
  doi = {10.48550/ARXIV.2302.09185},
  url = {https://arxiv.org/abs/2302.09185},
  author = {Lu,  Albert and Zhang,  Hongxin and Zhang,  Yanzhe and Wang,  Xuezhi and Yang,  Diyi},
  keywords = {Computation and Language (cs.CL),  Artificial Intelligence (cs.AI),  Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Bounding the Capabilities of Large Language Models in Open Text Generation with Prompt Constraints},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{roleplaying,
  doi = {10.48550/ARXIV.2310.00746},
  url = {https://arxiv.org/abs/2310.00746},
  author = {Wang,  Zekun Moore and Peng,  Zhongyuan and Que,  Haoran and Liu,  Jiaheng and Zhou,  Wangchunshu and Wu,  Yuhan and Guo,  Hongcheng and Gan,  Ruitong and Ni,  Zehao and Yang,  Jian and Zhang,  Man and Zhang,  Zhaoxiang and Ouyang,  Wanli and Xu,  Ke and Huang,  Stephen W. and Fu,  Jie and Peng,  Junran},
  keywords = {Computation and Language (cs.CL),  Artificial Intelligence (cs.AI),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {RoleLLM: Benchmarking,  Eliciting,  and Enhancing Role-Playing Abilities of Large Language Models},
  publisher = {arXiv},
  year = {2023},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{helpfulassistant,
  doi = {10.48550/ARXIV.2311.10054},
  url = {https://arxiv.org/abs/2311.10054},
  author = {Zheng,  Mingqian and Pei,  Jiaxin and Jurgens,  David},
  keywords = {Computation and Language (cs.CL),  Artificial Intelligence (cs.AI),  Computers and Society (cs.CY),  Human-Computer Interaction (cs.HC),  Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Is "A Helpful Assistant" the Best Role for Large Language Models? A Systematic Evaluation of Social Roles in System Prompts},
  publisher = {arXiv},
  year = {2023},
  copyright = {Creative Commons Attribution 4.0 International}
}

@article{Jiang2020,
  title = {How Can We Know What Language Models Know?},
  volume = {8},
  ISSN = {2307-387X},
  url = {http://dx.doi.org/10.1162/tacl_a_00324},
  DOI = {10.1162/tacl_a_00324},
  journal = {Transactions of the Association for Computational Linguistics},
  publisher = {MIT Press - Journals},
  author = {Jiang,  Zhengbao and Xu,  Frank F. and Araki,  Jun and Neubig,  Graham},
  year = {2020},
  month = dec,
  pages = {423–438}
}

@misc{su2022selectiveannotationmakeslanguage,
      title={Selective Annotation Makes Language Models Better Few-Shot Learners}, 
      author={Hongjin Su and Jungo Kasai and Chen Henry Wu and Weijia Shi and Tianlu Wang and Jiayi Xin and Rui Zhang and Mari Ostendorf and Luke Zettlemoyer and Noah A. Smith and Tao Yu},
      year={2022},
      eprint={2209.01975},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2209.01975}, 
}

@misc{gpt3,
  doi = {10.48550/ARXIV.2005.14165},
  url = {https://arxiv.org/abs/2005.14165},
  author = {Brown,  Tom B. and Mann,  Benjamin and Ryder,  Nick and Subbiah,  Melanie and Kaplan,  Jared and Dhariwal,  Prafulla and Neelakantan,  Arvind and Shyam,  Pranav and Sastry,  Girish and Askell,  Amanda and Agarwal,  Sandhini and Herbert-Voss,  Ariel and Krueger,  Gretchen and Henighan,  Tom and Child,  Rewon and Ramesh,  Aditya and Ziegler,  Daniel M. and Wu,  Jeffrey and Winter,  Clemens and Hesse,  Christopher and Chen,  Mark and Sigler,  Eric and Litwin,  Mateusz and Gray,  Scott and Chess,  Benjamin and Clark,  Jack and Berner,  Christopher and McCandlish,  Sam and Radford,  Alec and Sutskever,  Ilya and Amodei,  Dario},
  keywords = {Computation and Language (cs.CL),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Language Models are Few-Shot Learners},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{min2020ambigqaansweringambiguousopendomain,
      title={AmbigQA: Answering Ambiguous Open-domain Questions}, 
      author={Sewon Min and Julian Michael and Hannaneh Hajishirzi and Luke Zettlemoyer},
      year={2020},
      eprint={2004.10645},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2004.10645}, 
}

@misc{wei2023chainofthoughtpromptingelicitsreasoning,
      title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models}, 
      author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
      year={2023},
      eprint={2201.11903},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2201.11903}, 
}

@misc{liu2021makesgoodincontextexamples,
      title={What Makes Good In-Context Examples for GPT-$3$?}, 
      author={Jiachang Liu and Dinghan Shen and Yizhe Zhang and Bill Dolan and Lawrence Carin and Weizhu Chen},
      year={2021},
      eprint={2101.06804},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2101.06804}, 
}

@misc{talmor2019commonsenseqaquestionansweringchallenge,
      title={CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge}, 
      author={Alon Talmor and Jonathan Herzig and Nicholas Lourie and Jonathan Berant},
      year={2019},
      eprint={1811.00937},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1811.00937}, 
}

@misc{zhang2018recordbridginggaphuman,
      title={ReCoRD: Bridging the Gap between Human and Machine Commonsense Reading Comprehension}, 
      author={Sheng Zhang and Xiaodong Liu and Jingjing Liu and Jianfeng Gao and Kevin Duh and Benjamin Van Durme},
      year={2018},
      eprint={1810.12885},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1810.12885}, 
}

@misc{cobbe2021trainingverifierssolvemath,
      title={Training Verifiers to Solve Math Word Problems}, 
      author={Karl Cobbe and Vineet Kosaraju and Mohammad Bavarian and Mark Chen and Heewoo Jun and Lukasz Kaiser and Matthias Plappert and Jerry Tworek and Jacob Hilton and Reiichiro Nakano and Christopher Hesse and John Schulman},
      year={2021},
      eprint={2110.14168},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2110.14168}, 
}

@misc{zhou2023threadthoughtunravelingchaotic,
      title={Thread of Thought Unraveling Chaotic Contexts}, 
      author={Yucheng Zhou and Xiubo Geng and Tao Shen and Chongyang Tao and Guodong Long and Jian-Guang Lou and Jianbing Shen},
      year={2023},
      eprint={2311.08734},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.08734}, 
}

@misc{zheng2024stepbackevokingreasoning,
      title={Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models}, 
      author={Huaixiu Steven Zheng and Swaroop Mishra and Xinyun Chen and Heng-Tze Cheng and Ed H. Chi and Quoc V Le and Denny Zhou},
      year={2024},
      eprint={2310.06117},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2310.06117}, 
}

@misc{li2024dialoguepromptingpolicygradientbaseddiscrete,
      title={Dialogue for Prompting: a Policy-Gradient-Based Discrete Prompt Generation for Few-shot Learning}, 
      author={Chengzhengxu Li and Xiaoming Liu and Yichen Wang and Duyi Li and Yu Lan and Chao Shen},
      year={2024},
      eprint={2308.07272},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2308.07272}, 
}

@misc{patel2022questiondecompositionunitneed,
      title={Is a Question Decomposition Unit All We Need?}, 
      author={Pruthvi Patel and Swaroop Mishra and Mihir Parmar and Chitta Baral},
      year={2022},
      eprint={2205.12538},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2205.12538}, 
}

@misc{wang2023planandsolvepromptingimprovingzeroshot,
      title={Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models}, 
      author={Lei Wang and Wanyu Xu and Yihuai Lan and Zhiqiang Hu and Yunshi Lan and Roy Ka-Wei Lee and Ee-Peng Lim},
      year={2023},
      eprint={2305.04091},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.04091}, 
}

@misc{khalifa2023exploringdemonstrationensemblingincontext,
      title={Exploring Demonstration Ensembling for In-context Learning}, 
      author={Muhammad Khalifa and Lajanugen Logeswaran and Moontae Lee and Honglak Lee and Lu Wang},
      year={2023},
      eprint={2308.08780},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2308.08780}, 
}

@misc{wang2023selfconsistencyimproveschainthought,
      title={Self-Consistency Improves Chain of Thought Reasoning in Language Models}, 
      author={Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc Le and Ed Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou},
      year={2023},
      eprint={2203.11171},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.11171}, 
}

@inproceedings{parrots, author = {Bender, Emily M. and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret}, title = {On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?}, year = {2021}, isbn = {9781450383097}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, url = {https://doi.org/10.1145/3442188.3445922}, doi = {10.1145/3442188.3445922}, abstract = {The past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.}, booktitle = {Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency}, pages = {610–623}, numpages = {14}, location = {Virtual Event, Canada}, series = {FAccT '21} }


@misc{ouyang2022traininglanguagemodelsfollow,
      title={Training language models to follow instructions with human feedback}, 
      author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
      year={2022},
      eprint={2203.02155},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.02155}, 
}

@article{bai2024hallucination,
  title={Hallucination of multimodal large language models: A survey},
  author={Bai, Zechen and Wang, Pichao and Xiao, Tianjun and He, Tong and Han, Zongbo and Zhang, Zheng and Shou, Mike Zheng},
  journal={arXiv preprint arXiv:2404.18930},
  year={2024}
}

@misc{yuan2024rigorllmresilientguardrailslarge,
      title={RigorLLM: Resilient Guardrails for Large Language Models against Undesired Content}, 
      author={Zhuowen Yuan and Zidi Xiong and Yi Zeng and Ning Yu and Ruoxi Jia and Dawn Song and Bo Li},
      year={2024},
      eprint={2403.13031},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2403.13031}, 
}

@misc{dong2024buildingguardrailslargelanguage,
      title={Building Guardrails for Large Language Models}, 
      author={Yi Dong and Ronghui Mu and Gaojie Jin and Yi Qi and Jinwei Hu and Xingyu Zhao and Jie Meng and Wenjie Ruan and Xiaowei Huang},
      year={2024},
      eprint={2402.01822},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.01822}, 
}

@article{Trinh2024,
  title = {Solving olympiad geometry without human demonstrations},
  volume = {625},
  ISSN = {1476-4687},
  url = {http://dx.doi.org/10.1038/s41586-023-06747-5},
  DOI = {10.1038/s41586-023-06747-5},
  number = {7995},
  journal = {Nature},
  publisher = {Springer Science and Business Media LLC},
  author = {Trinh,  Trieu H. and Wu,  Yuhuai and Le,  Quoc V. and He,  He and Luong,  Thang},
  year = {2024},
  month = jan,
  pages = {476–482}
}

@article{wang2024evaluating,
  title={Evaluating Quality of Answers for Retrieval-Augmented Generation: A Strong LLM Is All You Need},
  author={Wang, Yang and Hernandez, Alberto Garcia and Kyslyi, Roman and Kersting, Nicholas},
  journal={arXiv preprint arXiv:2406.18064},
  year={2024}
}

@article{ding2024survey,
  title={A survey on rag meets llms: Towards retrieval-augmented large language models},
  author={Ding, Yujuan and Fan, Wenqi and Ning, Liangbo and Wang, Shijie and Li, Hengyun and Yin, Dawei and Chua, Tat-Seng and Li, Qing},
  journal={arXiv preprint arXiv:2405.06211},
  year={2024}
}

@misc{sumers2024cognitivearchitectureslanguageagents,
      title={Cognitive Architectures for Language Agents}, 
      author={Theodore R. Sumers and Shunyu Yao and Karthik Narasimhan and Thomas L. Griffiths},
      year={2024},
      eprint={2309.02427},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2309.02427}, 
}

@misc{patil2023gorillalargelanguagemodel,
      title={Gorilla: Large Language Model Connected with Massive APIs}, 
      author={Shishir G. Patil and Tianjun Zhang and Xin Wang and Joseph E. Gonzalez},
      year={2023},
      eprint={2305.15334},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.15334}, 
}

@misc{selfinstruct,
  doi = {10.48550/ARXIV.2212.10560},
  url = {https://arxiv.org/abs/2212.10560},
  author = {Wang,  Yizhong and Kordi,  Yeganeh and Mishra,  Swaroop and Liu,  Alisa and Smith,  Noah A. and Khashabi,  Daniel and Hajishirzi,  Hannaneh},
  keywords = {Computation and Language (cs.CL),  Artificial Intelligence (cs.AI),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Self-Instruct: Aligning Language Models with Self-Generated Instructions},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution 4.0 International}
}

@misc{aiasos,
  doi = {10.48550/ARXIV.2403.16971},
  url = {https://arxiv.org/abs/2403.16971},
  author = {Mei,  Kai and Li,  Zelong and Xu,  Shuyuan and Ye,  Ruosong and Ge,  Yingqiang and Zhang,  Yongfeng},
  keywords = {Operating Systems (cs.OS),  Artificial Intelligence (cs.AI),  Computation and Language (cs.CL),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {AIOS: LLM Agent Operating System},
  publisher = {arXiv},
  year = {2024},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}

@misc{qin2023toolllmfacilitatinglargelanguage,
      title={ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs}, 
      author={Yujia Qin and Shihao Liang and Yining Ye and Kunlun Zhu and Lan Yan and Yaxi Lu and Yankai Lin and Xin Cong and Xiangru Tang and Bill Qian and Sihan Zhao and Lauren Hong and Runchu Tian and Ruobing Xie and Jie Zhou and Mark Gerstein and Dahai Li and Zhiyuan Liu and Maosong Sun},
      year={2023},
      eprint={2307.16789},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2307.16789}, 
}

@misc{zheng2023judgingllmasajudgemtbenchchatbot,
      title={Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena}, 
      author={Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric P. Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
      year={2023},
      eprint={2306.05685},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2306.05685}, 
}